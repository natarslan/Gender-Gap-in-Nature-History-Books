{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Source 0: https://data36.com/scrape-multiple-web-pages-beautiful-soup-tutorial/\n",
    "# Source 1: https://data36.com/scrape-multiple-web-pages-beautiful-soup-tutorial/\n",
    "# Source 2: https://medium.com/codex/web-scraping-using-beautifulsoup-pushing-data-to-mysql-database-9de6af06e7b8\n",
    "# A combination of these three sources made a lot of sense to me\n",
    "\n",
    "page = 1\n",
    "titles = []\n",
    "authors = []\n",
    "price = []\n",
    "date = []\n",
    "while page != 333:\n",
    "    url = f\"https://www.bookdepository.com/category/2985/Natural-History/browse/viewmode/all?page={page}\"\n",
    "    response = requests.get(url)\n",
    "    html = response.content\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    \n",
    "    # we loop through all h3 elements with the class of title\n",
    "    for h3 in soup.find_all(\"h3\", class_=\"title\"):\n",
    "        titles.append(h3.get_text(strip=True))\n",
    "    \n",
    "    #for p in soup.find_all(\"p\", class_=\"author\"):\n",
    "    for p in soup.find_all(\"p\", class_ = \"author\"):\n",
    "        authors.append(p.get_text(strip=True))\n",
    "        \n",
    "    #for div in soup.find_all(\"div\", class_ = \"price-wrap\"):\n",
    "        #price.append(div.get_text(strip=True))\n",
    "    \n",
    "    for p in soup.find_all(\"p\", class_ = \"published\"):\n",
    "        date.append(p.get_text(strip=True))\n",
    "        \n",
    "    \n",
    "    #for a in soup.find_all(\"a\", class_ = \"btn btn-sm btn-primary add-to-basket\"):\n",
    "        #price.append(a.get_text(strip=True)) #get(\"data-price\"))\n",
    "        \n",
    "    \n",
    "    page = page + 1\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>titles</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stephen Hawking</td>\n",
       "      <td>A Brief History Of Time</td>\n",
       "      <td>20 Jan 2015</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>James Bowen</td>\n",
       "      <td>A Street Cat Named Bob</td>\n",
       "      <td>23 Jan 2013</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Peter Wohlleben</td>\n",
       "      <td>The Hidden Life of Trees</td>\n",
       "      <td>22 Nov 2019</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Raynor Winn</td>\n",
       "      <td>The Salt Path</td>\n",
       "      <td>31 Jan 2019</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Catherine D. Hughes</td>\n",
       "      <td>Little Kids First Big Book of Dinosaurs</td>\n",
       "      <td>16 Aug 2018</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               authors                                   titles         date  \\\n",
       "0      Stephen Hawking                  A Brief History Of Time  20 Jan 2015   \n",
       "1          James Bowen                   A Street Cat Named Bob  23 Jan 2013   \n",
       "2      Peter Wohlleben                 The Hidden Life of Trees  22 Nov 2019   \n",
       "3          Raynor Winn                            The Salt Path  31 Jan 2019   \n",
       "4  Catherine D. Hughes  Little Kids First Big Book of Dinosaurs  16 Aug 2018   \n",
       "\n",
       "   year  \n",
       "0  2015  \n",
       "1  2013  \n",
       "2  2019  \n",
       "3  2019  \n",
       "4  2018  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(\n",
    "    {'authors': authors,\n",
    "     'titles': titles,\n",
    "     'date': date\n",
    "    })\n",
    "\n",
    "# Add a year column to dataframe and get only the year data from date column\n",
    "df['year'] = df['date'].str.strip().str[-4:]\n",
    "\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the NaN values to prevent future errors\n",
    "for i in range(len(df['authors'])):\n",
    "    \n",
    "    author = df['authors'][i]\n",
    "    #boolean = pd.isna(author) # true or false\n",
    "    boolean = df['authors'][i] == ''\n",
    "    \n",
    "    if boolean == False:\n",
    "        df['authors'][i] = df['authors'][i]\n",
    "    else:\n",
    "        df['authors'][i] = \"No Author\"\n",
    "        #print('done')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data\n",
    "df_2021 = df[(df['year'] == '2021')]\n",
    "df_2020 = df[(df['year'] == '2020')]\n",
    "df_2019 = df[(df['year'] == '2019')]\n",
    "df_2018 = df[(df['year'] == '2018')]\n",
    "df_2017 = df[(df['year'] == '2017')]\n",
    "df_2016 = df[(df['year'] == '2016')]\n",
    "df_2015 = df[(df['year'] == '2015')]\n",
    "\n",
    "# Export to CSV & Import it\n",
    "df.to_csv('/Users/nat/Desktop/Code/Code Projects/Book-Gender/Data/Bookdepository/NaturalHistory-Bookdepository-All.csv')\n",
    "df_2021.to_csv('/Users/nat/Desktop/Code/Code Projects/Book-Gender/Data/Bookdepository/NaturalHistory-Bookdepository-2021.csv')\n",
    "df_2020.to_csv('/Users/nat/Desktop/Code/Code Projects/Book-Gender/Data/Bookdepository/NaturalHistory-Bookdepository-2020.csv')\n",
    "df_2019.to_csv('/Users/nat/Desktop/Code/Code Projects/Book-Gender/Data/Bookdepository/NaturalHistory-Bookdepository-2019.csv')\n",
    "df_2018.to_csv('/Users/nat/Desktop/Code/Code Projects/Book-Gender/Data/Bookdepository/NaturalHistory-Bookdepository-2018.csv')\n",
    "df_2017.to_csv('/Users/nat/Desktop/Code/Code Projects/Book-Gender/Data/Bookdepository/NaturalHistory-Bookdepository-2017.csv')\n",
    "df_2016.to_csv('/Users/nat/Desktop/Code/Code Projects/Book-Gender/Data/Bookdepository/NaturalHistory-Bookdepository-2016.csv')\n",
    "df_2015.to_csv('/Users/nat/Desktop/Code/Code Projects/Book-Gender/Data/Bookdepository/NaturalHistory-Bookdepository-2015.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_2021)) # 982\n",
    "print(len(df_2020)) # 889\n",
    "print(len(df_2019)) # 748\n",
    "print(len(df_2018)) # 762\n",
    "print(len(df_2017)) # 696\n",
    "print(len(df_2016)) # 665\n",
    "print(len(df_2015)) # 690"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CSV\n",
    "#books_2021 = pd.read_csv(\".....csv\", dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
